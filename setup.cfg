[metadata]
name = AttentionLikelihood
description = Code for the ICLR23 paper "Attention-likelihood relationship in Transformers"
url = https://github.com/Flegyas/AttentionLikelihood
long_description = file: README.md
author = Valentino Maiorca
author_email = valentino@maiorca.xyz
keywords = python
license = MIT Licence

[options]
zip_safe = False
include_package_data = True
package_dir=
    =src
packages=find:
install_requires =
    nn-template-core==0.2.*

    # Add project specific dependencies
    # Stuff easy to break with updates
    lightning==2.0.*
    torchmetrics==0.11.*
    hydra-core
    wandb
    streamlit
    # hydra-joblib-launcher

    # Stable stuff usually backward compatible
    rich
    dvc
    python-dotenv
    matplotlib
    stqdm
    jupyter
    spacy

[options.packages.find]
where=src

[options.package_data]
* = *.txt, *.md

[options.extras_require]
test =
    pytest
    pytest-cov

dev =
    black
    flake8
    isort
    pre-commit
    bandit
    %(test)s
