{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">2023-04-14 17:20:59 </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Created a temporary directory at              <a href=\"file:///home/valentino/miniconda3/envs/attlike/lib/python3.10/site-packages/torch/distributed/nn/jit/instantiator.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">torch.distributed.nn.jit.instantiator</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/valentino/miniconda3/envs/attlike/lib/python3.10/site-packages/torch/distributed/nn/jit/instantiator.py#21\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">21</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #800080; text-decoration-color: #800080\">/tmp/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">tmp400xhr4f</span>                              <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                                        </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m2023-04-14 17:20:59\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Created a temporary directory at              \u001b]8;id=73227;file:///home/valentino/miniconda3/envs/attlike/lib/python3.10/site-packages/torch/distributed/nn/jit/instantiator.py\u001b\\\u001b[2mtorch.distributed.nn.jit.instantiator\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=255017;file:///home/valentino/miniconda3/envs/attlike/lib/python3.10/site-packages/torch/distributed/nn/jit/instantiator.py#21\u001b\\\u001b[2m21\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[35m/tmp/\u001b[0m\u001b[95mtmp400xhr4f\u001b[0m                              \u001b[2m                                        \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Writing                                       <a href=\"file:///home/valentino/miniconda3/envs/attlike/lib/python3.10/site-packages/torch/distributed/nn/jit/instantiator.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">torch.distributed.nn.jit.instantiator</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/valentino/miniconda3/envs/attlike/lib/python3.10/site-packages/torch/distributed/nn/jit/instantiator.py#76\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">76</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #800080; text-decoration-color: #800080\">/tmp/tmp400xhr4f/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">_remote_module_non_scriptabl</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                                        </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">e.py</span>                                          <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                                        </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Writing                                       \u001b]8;id=860361;file:///home/valentino/miniconda3/envs/attlike/lib/python3.10/site-packages/torch/distributed/nn/jit/instantiator.py\u001b\\\u001b[2mtorch.distributed.nn.jit.instantiator\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=48779;file:///home/valentino/miniconda3/envs/attlike/lib/python3.10/site-packages/torch/distributed/nn/jit/instantiator.py#76\u001b\\\u001b[2m76\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[35m/tmp/tmp400xhr4f/\u001b[0m\u001b[95m_remote_module_non_scriptabl\u001b[0m \u001b[2m                                        \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[95me.py\u001b[0m                                          \u001b[2m                                        \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from attlike.utils import load_data, LikelihoodMode\n",
    "from pathlib import Path\n",
    "from datasets import DatasetDict\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from nn_core.common import PROJECT_ROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR: Path = PROJECT_ROOT / \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['low', 'lowest', 'high', 'real', 'highest', 'mid'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "likelihood2encoder2data = DatasetDict(\n",
    "    {\n",
    "        likelihood_path.name: DatasetDict.load_from_disk(likelihood_path)\n",
    "        for likelihood_path in (DATA_DIR / \"likelihoods\").iterdir()\n",
    "        if not likelihood_path.name.endswith(\".json\")\n",
    "    }\n",
    ")\n",
    "likelihood2encoder2data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: she was able to program her computer | able - Drop\n",
      "Sentence: we were at last able to buy a car | able - physical\n",
      "Sentence: able to get a grant for the project | able - protr\n",
      "Sentence: unable to get to town without a car | unable - MIC Hau\n",
      "Sentence: the abaxial surface of a leaf is the underside or side facing away from the stem | abaxial - KS IdleWeapons\n",
      "Sentence: the upper side of a leaf is known as the adaxial surface | adaxial - OSH RankedIGHTS\n",
      "Sentence: a potted version of a novel | potted - Alias GEAR\n",
      "Sentence: she is a living doll | living - headers\n",
      "Sentence: scared the living daylights out of them | living - operator\n",
      "Sentence: beat the living hell out of him | living - Modes\n",
      "Sentence: as absorbent as a sponge | absorbent - Flying Swordsman\n"
     ]
    }
   ],
   "source": [
    "likelihood_mode1 = \"real\"\n",
    "likelihood_mode2 = LikelihoodMode.LOWEST\n",
    "encoder: str = \"roberta-base\"\n",
    "n: int = 10\n",
    "\n",
    "for i, (sample1, sample2) in enumerate(\n",
    "    zip(\n",
    "        likelihood2encoder2data[likelihood_mode1][encoder],\n",
    "        likelihood2encoder2data[likelihood_mode2][encoder],\n",
    "    )\n",
    "):\n",
    "    if sample1[\"lemma\"].strip() != sample2[\"lemma\"].strip():\n",
    "        print(f\"Sentence: {sample1['sentence']} | {sample1['lemma']} - {sample2['lemma'].strip()}\")\n",
    "\n",
    "    if i >= n:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.functional import spearman_corrcoef as corrcoef\n",
    "\n",
    "correlation_df = {\n",
    "    \"likelihood_mode\": [],\n",
    "    \"inner_likelihood\": [],\n",
    "    \"attention\": [],\n",
    "    \"inner_attention\": [],\n",
    "    \"outer_attention\": [],\n",
    "    \"encoder\": [],\n",
    "    \"layer\": [],\n",
    "    \"correlation\": [],\n",
    "    \"inner_likelihood_std\": [],\n",
    "    \"attention_std\": [],\n",
    "    \"inner_attention_std\": [],\n",
    "    \"outer_attention_std\": [],\n",
    "}\n",
    "\n",
    "for likelihood, encoder2data in list(likelihood2encoder2data.items()):\n",
    "    x = []\n",
    "    for encoder_name, encoder_data in list(encoder2data.items()):\n",
    "        for layer in range(50):\n",
    "            if f\"inner_attention_{layer}_mean\" not in encoder_data.column_names:\n",
    "                continue\n",
    "            correlation_df[\"likelihood_mode\"].append(likelihood)\n",
    "            correlation_df[\"inner_likelihood\"].append(encoder_data[\"inner_likelihoods_mean\"].mean().item())\n",
    "            correlation_df[\"inner_likelihood_std\"].append(encoder_data[\"inner_likelihoods_mean\"].std().item())\n",
    "            correlation_df[\"inner_attention\"].append(encoder_data[f\"inner_attention_{layer}_mean\"].mean().item())\n",
    "            correlation_df[\"inner_attention_std\"].append(encoder_data[f\"inner_attention_{layer}_mean\"].std().item())\n",
    "            correlation_df[\"outer_attention\"].append(encoder_data[f\"outer_attention_{layer}_mean\"].mean().item())\n",
    "            correlation_df[\"outer_attention_std\"].append(encoder_data[f\"outer_attention_{layer}_mean\"].std().item())\n",
    "            correlation_df[\"attention\"].append(encoder_data[f\"attention_{layer}_mean\"].mean().item())\n",
    "            correlation_df[\"attention_std\"].append(encoder_data[f\"attention_{layer}_mean\"].std().item())\n",
    "            correlation_df[\"encoder\"].append(encoder_name)\n",
    "            correlation_df[\"layer\"].append(layer)\n",
    "            correlation = corrcoef(\n",
    "                encoder_data[\"inner_likelihoods_mean\"].squeeze(-1),\n",
    "                encoder_data[f\"inner_attention_{layer}_mean\"].squeeze(-1),\n",
    "            ).item()\n",
    "            correlation_df[\"correlation\"].append(correlation)\n",
    "correlation_df = pd.DataFrame(correlation_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>encoder</th>\n",
       "      <th>layer</th>\n",
       "      <th>correlation</th>\n",
       "      <th>inner_likelihood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>9</td>\n",
       "      <td>0.642901</td>\n",
       "      <td>0.095786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>distilbert-base-uncased</td>\n",
       "      <td>4</td>\n",
       "      <td>0.687584</td>\n",
       "      <td>0.016773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>roberta-base</td>\n",
       "      <td>11</td>\n",
       "      <td>0.801689</td>\n",
       "      <td>0.072483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>roberta-large</td>\n",
       "      <td>23</td>\n",
       "      <td>0.822567</td>\n",
       "      <td>0.054967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>xlm-roberta-base</td>\n",
       "      <td>11</td>\n",
       "      <td>0.766631</td>\n",
       "      <td>0.017382</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     encoder  layer  correlation  inner_likelihood\n",
       "75         bert-base-uncased      9     0.642901          0.095786\n",
       "130  distilbert-base-uncased      4     0.687584          0.016773\n",
       "155             roberta-base     11     0.801689          0.072483\n",
       "191            roberta-large     23     0.822567          0.054967\n",
       "365         xlm-roberta-base     11     0.766631          0.017382"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = (\n",
    "    correlation_df.groupby([\"encoder\",])[\n",
    "        \"correlation\"\n",
    "    ].transform(max)\n",
    "    == correlation_df[\"correlation\"]\n",
    ")\n",
    "correlation_df[idx][[\"encoder\", \"layer\", \"correlation\", \"inner_likelihood\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bert-base-uncased': 0.663658618927002,\n",
       " 'distilbert-base-uncased': 0.7850713133811951,\n",
       " 'roberta-base': 0.9384443163871765,\n",
       " 'roberta-large': 0.947394609451294,\n",
       " 'xlm-roberta-base': 0.9425700306892395}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_likelihoods = (\n",
    "    correlation_df[correlation_df.likelihood_mode == \"real\"]\n",
    "    .groupby(\"encoder\")[\"inner_likelihood\"]\n",
    "    .aggregate([\"max\"])\n",
    "    .to_dict()[\"max\"]\n",
    ")\n",
    "real_likelihoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>likelihood_mode</th>\n",
       "      <th>inner_likelihood</th>\n",
       "      <th>attention</th>\n",
       "      <th>inner_attention</th>\n",
       "      <th>outer_attention</th>\n",
       "      <th>encoder</th>\n",
       "      <th>layer</th>\n",
       "      <th>correlation</th>\n",
       "      <th>inner_likelihood_std</th>\n",
       "      <th>attention_std</th>\n",
       "      <th>inner_attention_std</th>\n",
       "      <th>outer_attention_std</th>\n",
       "      <th>inner_likelihood_real</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>low</td>\n",
       "      <td>0.14524</td>\n",
       "      <td>0.09881</td>\n",
       "      <td>0.113051</td>\n",
       "      <td>0.098257</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003345</td>\n",
       "      <td>0.24419</td>\n",
       "      <td>0.025692</td>\n",
       "      <td>0.034307</td>\n",
       "      <td>0.025969</td>\n",
       "      <td>0.663659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>low</td>\n",
       "      <td>0.14524</td>\n",
       "      <td>0.09881</td>\n",
       "      <td>0.053262</td>\n",
       "      <td>0.100248</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>1</td>\n",
       "      <td>0.037827</td>\n",
       "      <td>0.24419</td>\n",
       "      <td>0.025692</td>\n",
       "      <td>0.019007</td>\n",
       "      <td>0.026191</td>\n",
       "      <td>0.663659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>low</td>\n",
       "      <td>0.14524</td>\n",
       "      <td>0.09881</td>\n",
       "      <td>0.084208</td>\n",
       "      <td>0.099141</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>2</td>\n",
       "      <td>0.448137</td>\n",
       "      <td>0.24419</td>\n",
       "      <td>0.025692</td>\n",
       "      <td>0.025533</td>\n",
       "      <td>0.026237</td>\n",
       "      <td>0.663659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>low</td>\n",
       "      <td>0.14524</td>\n",
       "      <td>0.09881</td>\n",
       "      <td>0.054403</td>\n",
       "      <td>0.099830</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>3</td>\n",
       "      <td>0.256296</td>\n",
       "      <td>0.24419</td>\n",
       "      <td>0.025692</td>\n",
       "      <td>0.023566</td>\n",
       "      <td>0.026345</td>\n",
       "      <td>0.663659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>low</td>\n",
       "      <td>0.14524</td>\n",
       "      <td>0.09881</td>\n",
       "      <td>0.064569</td>\n",
       "      <td>0.099763</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>4</td>\n",
       "      <td>0.084421</td>\n",
       "      <td>0.24419</td>\n",
       "      <td>0.025692</td>\n",
       "      <td>0.021179</td>\n",
       "      <td>0.026200</td>\n",
       "      <td>0.663659</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  likelihood_mode  inner_likelihood  attention  inner_attention  \\\n",
       "0             low           0.14524    0.09881         0.113051   \n",
       "1             low           0.14524    0.09881         0.053262   \n",
       "2             low           0.14524    0.09881         0.084208   \n",
       "3             low           0.14524    0.09881         0.054403   \n",
       "4             low           0.14524    0.09881         0.064569   \n",
       "\n",
       "   outer_attention            encoder  layer  correlation  \\\n",
       "0         0.098257  bert-base-uncased      0     0.003345   \n",
       "1         0.100248  bert-base-uncased      1     0.037827   \n",
       "2         0.099141  bert-base-uncased      2     0.448137   \n",
       "3         0.099830  bert-base-uncased      3     0.256296   \n",
       "4         0.099763  bert-base-uncased      4     0.084421   \n",
       "\n",
       "   inner_likelihood_std  attention_std  inner_attention_std  \\\n",
       "0               0.24419       0.025692             0.034307   \n",
       "1               0.24419       0.025692             0.019007   \n",
       "2               0.24419       0.025692             0.025533   \n",
       "3               0.24419       0.025692             0.023566   \n",
       "4               0.24419       0.025692             0.021179   \n",
       "\n",
       "   outer_attention_std  inner_likelihood_real  \n",
       "0             0.025969               0.663659  \n",
       "1             0.026191               0.663659  \n",
       "2             0.026237               0.663659  \n",
       "3             0.026345               0.663659  \n",
       "4             0.026200               0.663659  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlation_df[\"inner_likelihood_real\"] = correlation_df[\"encoder\"].map(real_likelihoods)\n",
    "correlation_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "264"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lower_likelihood_df = correlation_df[correlation_df.inner_likelihood < correlation_df.inner_likelihood_real]\n",
    "len(lower_likelihood_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>encoder</th>\n",
       "      <th>layer</th>\n",
       "      <th>attention</th>\n",
       "      <th>attention_std</th>\n",
       "      <th>inner_attention</th>\n",
       "      <th>inner_attention_std</th>\n",
       "      <th>outer_attention</th>\n",
       "      <th>outer_attention_std</th>\n",
       "      <th>inner_likelihood</th>\n",
       "      <th>inner_likelihood_std</th>\n",
       "      <th>correlation</th>\n",
       "      <th>likelihood_mode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>9</td>\n",
       "      <td>0.098810</td>\n",
       "      <td>0.025692</td>\n",
       "      <td>0.062833</td>\n",
       "      <td>0.041480</td>\n",
       "      <td>0.099721</td>\n",
       "      <td>0.026314</td>\n",
       "      <td>0.095786</td>\n",
       "      <td>0.197539</td>\n",
       "      <td>0.642901</td>\n",
       "      <td>lowest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>distilbert-base-uncased</td>\n",
       "      <td>4</td>\n",
       "      <td>0.098810</td>\n",
       "      <td>0.025692</td>\n",
       "      <td>0.045426</td>\n",
       "      <td>0.035298</td>\n",
       "      <td>0.099993</td>\n",
       "      <td>0.026461</td>\n",
       "      <td>0.016773</td>\n",
       "      <td>0.068814</td>\n",
       "      <td>0.687584</td>\n",
       "      <td>lowest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>roberta-base</td>\n",
       "      <td>11</td>\n",
       "      <td>0.099556</td>\n",
       "      <td>0.024887</td>\n",
       "      <td>0.042647</td>\n",
       "      <td>0.032833</td>\n",
       "      <td>0.100869</td>\n",
       "      <td>0.025637</td>\n",
       "      <td>0.072483</td>\n",
       "      <td>0.173935</td>\n",
       "      <td>0.801689</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>roberta-large</td>\n",
       "      <td>23</td>\n",
       "      <td>0.099556</td>\n",
       "      <td>0.024887</td>\n",
       "      <td>0.046074</td>\n",
       "      <td>0.035148</td>\n",
       "      <td>0.100755</td>\n",
       "      <td>0.025544</td>\n",
       "      <td>0.054967</td>\n",
       "      <td>0.149300</td>\n",
       "      <td>0.822567</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>xlm-roberta-base</td>\n",
       "      <td>11</td>\n",
       "      <td>0.089392</td>\n",
       "      <td>0.023990</td>\n",
       "      <td>0.050840</td>\n",
       "      <td>0.033801</td>\n",
       "      <td>0.090406</td>\n",
       "      <td>0.024606</td>\n",
       "      <td>0.017382</td>\n",
       "      <td>0.070976</td>\n",
       "      <td>0.766631</td>\n",
       "      <td>mid</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     encoder  layer  attention  attention_std  \\\n",
       "75         bert-base-uncased      9   0.098810       0.025692   \n",
       "130  distilbert-base-uncased      4   0.098810       0.025692   \n",
       "155             roberta-base     11   0.099556       0.024887   \n",
       "191            roberta-large     23   0.099556       0.024887   \n",
       "365         xlm-roberta-base     11   0.089392       0.023990   \n",
       "\n",
       "     inner_attention  inner_attention_std  outer_attention  \\\n",
       "75          0.062833             0.041480         0.099721   \n",
       "130         0.045426             0.035298         0.099993   \n",
       "155         0.042647             0.032833         0.100869   \n",
       "191         0.046074             0.035148         0.100755   \n",
       "365         0.050840             0.033801         0.090406   \n",
       "\n",
       "     outer_attention_std  inner_likelihood  inner_likelihood_std  correlation  \\\n",
       "75              0.026314          0.095786              0.197539     0.642901   \n",
       "130             0.026461          0.016773              0.068814     0.687584   \n",
       "155             0.025637          0.072483              0.173935     0.801689   \n",
       "191             0.025544          0.054967              0.149300     0.822567   \n",
       "365             0.024606          0.017382              0.070976     0.766631   \n",
       "\n",
       "    likelihood_mode  \n",
       "75           lowest  \n",
       "130          lowest  \n",
       "155            high  \n",
       "191            high  \n",
       "365             mid  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_idx = (\n",
    "    lower_likelihood_df.groupby([\"encoder\",])[\n",
    "        \"correlation\"\n",
    "    ].transform(max)\n",
    "    == lower_likelihood_df[\"correlation\"]\n",
    ")\n",
    "min_idx = (\n",
    "    lower_likelihood_df.groupby([\"encoder\",])[\n",
    "        \"correlation\"\n",
    "    ].transform(min)\n",
    "    == lower_likelihood_df[\"correlation\"]\n",
    ")\n",
    "\n",
    "max_lower_likelihood_df = lower_likelihood_df[max_idx].copy()\n",
    "max_lower_likelihood_df[\"target_correlation\"] = \"max\"\n",
    "\n",
    "min_lower_likelihood_df = lower_likelihood_df[min_idx].copy()\n",
    "min_lower_likelihood_df[\"target_correlation\"] = \"min\"\n",
    "\n",
    "# perturbed_df = pd.concat([max_lower_likelihood_df, min_lower_likelihood_df])\n",
    "perturbed_df = max_lower_likelihood_df\n",
    "perturbed_df = perturbed_df[perturbed_df.encoder != \"albert-base-v2\"]\n",
    "perturbed_df = perturbed_df[\n",
    "    [\n",
    "        \"encoder\",\n",
    "        # \"target_correlation\",\n",
    "        \"layer\",\n",
    "        \"attention\",\n",
    "        \"attention_std\",\n",
    "        \"inner_attention\",\n",
    "        \"inner_attention_std\",\n",
    "        \"outer_attention\",\n",
    "        \"outer_attention_std\",\n",
    "        \"inner_likelihood\",\n",
    "        \"inner_likelihood_std\",\n",
    "        \"correlation\",\n",
    "        \"likelihood_mode\",\n",
    "    ]\n",
    "]\n",
    "perturbed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_df = correlation_df[(correlation_df[\"likelihood_mode\"] == \"real\")]\n",
    "real_df = real_df[\n",
    "    [\n",
    "        \"encoder\",\n",
    "        # \"target_correlation\",\n",
    "        \"layer\",\n",
    "        \"attention\",\n",
    "        \"attention_std\",\n",
    "        \"inner_attention\",\n",
    "        \"inner_attention_std\",\n",
    "        \"outer_attention\",\n",
    "        \"outer_attention_std\",\n",
    "        \"inner_likelihood\",\n",
    "        \"inner_likelihood_std\",\n",
    "        \"correlation\",\n",
    "        \"likelihood_mode\",\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>encoder</th>\n",
       "      <th>layer</th>\n",
       "      <th>attention_real</th>\n",
       "      <th>attention_std_real</th>\n",
       "      <th>inner_attention_real</th>\n",
       "      <th>inner_attention_std_real</th>\n",
       "      <th>outer_attention_real</th>\n",
       "      <th>outer_attention_std_real</th>\n",
       "      <th>inner_likelihood_real</th>\n",
       "      <th>inner_likelihood_std_real</th>\n",
       "      <th>...</th>\n",
       "      <th>attention_perturbed</th>\n",
       "      <th>attention_std_perturbed</th>\n",
       "      <th>inner_attention_perturbed</th>\n",
       "      <th>inner_attention_std_perturbed</th>\n",
       "      <th>outer_attention_perturbed</th>\n",
       "      <th>outer_attention_std_perturbed</th>\n",
       "      <th>inner_likelihood_perturbed</th>\n",
       "      <th>inner_likelihood_std_perturbed</th>\n",
       "      <th>correlation_perturbed</th>\n",
       "      <th>likelihood_mode_perturbed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>9</td>\n",
       "      <td>0.098810</td>\n",
       "      <td>0.025692</td>\n",
       "      <td>0.074987</td>\n",
       "      <td>0.032488</td>\n",
       "      <td>0.099916</td>\n",
       "      <td>0.026053</td>\n",
       "      <td>0.663659</td>\n",
       "      <td>0.356065</td>\n",
       "      <td>...</td>\n",
       "      <td>0.098810</td>\n",
       "      <td>0.025692</td>\n",
       "      <td>0.062833</td>\n",
       "      <td>0.041480</td>\n",
       "      <td>0.099721</td>\n",
       "      <td>0.026314</td>\n",
       "      <td>0.095786</td>\n",
       "      <td>0.197539</td>\n",
       "      <td>0.642901</td>\n",
       "      <td>lowest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>roberta-base</td>\n",
       "      <td>11</td>\n",
       "      <td>0.099556</td>\n",
       "      <td>0.024887</td>\n",
       "      <td>0.124329</td>\n",
       "      <td>0.047694</td>\n",
       "      <td>0.099334</td>\n",
       "      <td>0.025083</td>\n",
       "      <td>0.938444</td>\n",
       "      <td>0.197165</td>\n",
       "      <td>...</td>\n",
       "      <td>0.099556</td>\n",
       "      <td>0.024887</td>\n",
       "      <td>0.042647</td>\n",
       "      <td>0.032833</td>\n",
       "      <td>0.100869</td>\n",
       "      <td>0.025637</td>\n",
       "      <td>0.072483</td>\n",
       "      <td>0.173935</td>\n",
       "      <td>0.801689</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>xlm-roberta-base</td>\n",
       "      <td>11</td>\n",
       "      <td>0.089392</td>\n",
       "      <td>0.023990</td>\n",
       "      <td>0.131850</td>\n",
       "      <td>0.062842</td>\n",
       "      <td>0.088980</td>\n",
       "      <td>0.024026</td>\n",
       "      <td>0.942570</td>\n",
       "      <td>0.175600</td>\n",
       "      <td>...</td>\n",
       "      <td>0.089392</td>\n",
       "      <td>0.023990</td>\n",
       "      <td>0.050840</td>\n",
       "      <td>0.033801</td>\n",
       "      <td>0.090406</td>\n",
       "      <td>0.024606</td>\n",
       "      <td>0.017382</td>\n",
       "      <td>0.070976</td>\n",
       "      <td>0.766631</td>\n",
       "      <td>mid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>roberta-large</td>\n",
       "      <td>23</td>\n",
       "      <td>0.099556</td>\n",
       "      <td>0.024887</td>\n",
       "      <td>0.133954</td>\n",
       "      <td>0.040175</td>\n",
       "      <td>0.099075</td>\n",
       "      <td>0.025067</td>\n",
       "      <td>0.947395</td>\n",
       "      <td>0.171740</td>\n",
       "      <td>...</td>\n",
       "      <td>0.099556</td>\n",
       "      <td>0.024887</td>\n",
       "      <td>0.046074</td>\n",
       "      <td>0.035148</td>\n",
       "      <td>0.100755</td>\n",
       "      <td>0.025544</td>\n",
       "      <td>0.054967</td>\n",
       "      <td>0.149300</td>\n",
       "      <td>0.822567</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>distilbert-base-uncased</td>\n",
       "      <td>4</td>\n",
       "      <td>0.098810</td>\n",
       "      <td>0.025692</td>\n",
       "      <td>0.064540</td>\n",
       "      <td>0.022500</td>\n",
       "      <td>0.100178</td>\n",
       "      <td>0.026117</td>\n",
       "      <td>0.785071</td>\n",
       "      <td>0.292972</td>\n",
       "      <td>...</td>\n",
       "      <td>0.098810</td>\n",
       "      <td>0.025692</td>\n",
       "      <td>0.045426</td>\n",
       "      <td>0.035298</td>\n",
       "      <td>0.099993</td>\n",
       "      <td>0.026461</td>\n",
       "      <td>0.016773</td>\n",
       "      <td>0.068814</td>\n",
       "      <td>0.687584</td>\n",
       "      <td>lowest</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   encoder  layer  attention_real  attention_std_real  \\\n",
       "0        bert-base-uncased      9        0.098810            0.025692   \n",
       "1             roberta-base     11        0.099556            0.024887   \n",
       "2         xlm-roberta-base     11        0.089392            0.023990   \n",
       "3            roberta-large     23        0.099556            0.024887   \n",
       "4  distilbert-base-uncased      4        0.098810            0.025692   \n",
       "\n",
       "   inner_attention_real  inner_attention_std_real  outer_attention_real  \\\n",
       "0              0.074987                  0.032488              0.099916   \n",
       "1              0.124329                  0.047694              0.099334   \n",
       "2              0.131850                  0.062842              0.088980   \n",
       "3              0.133954                  0.040175              0.099075   \n",
       "4              0.064540                  0.022500              0.100178   \n",
       "\n",
       "   outer_attention_std_real  inner_likelihood_real  inner_likelihood_std_real  \\\n",
       "0                  0.026053               0.663659                   0.356065   \n",
       "1                  0.025083               0.938444                   0.197165   \n",
       "2                  0.024026               0.942570                   0.175600   \n",
       "3                  0.025067               0.947395                   0.171740   \n",
       "4                  0.026117               0.785071                   0.292972   \n",
       "\n",
       "   ...  attention_perturbed attention_std_perturbed  \\\n",
       "0  ...             0.098810                0.025692   \n",
       "1  ...             0.099556                0.024887   \n",
       "2  ...             0.089392                0.023990   \n",
       "3  ...             0.099556                0.024887   \n",
       "4  ...             0.098810                0.025692   \n",
       "\n",
       "   inner_attention_perturbed  inner_attention_std_perturbed  \\\n",
       "0                   0.062833                       0.041480   \n",
       "1                   0.042647                       0.032833   \n",
       "2                   0.050840                       0.033801   \n",
       "3                   0.046074                       0.035148   \n",
       "4                   0.045426                       0.035298   \n",
       "\n",
       "   outer_attention_perturbed  outer_attention_std_perturbed  \\\n",
       "0                   0.099721                       0.026314   \n",
       "1                   0.100869                       0.025637   \n",
       "2                   0.090406                       0.024606   \n",
       "3                   0.100755                       0.025544   \n",
       "4                   0.099993                       0.026461   \n",
       "\n",
       "   inner_likelihood_perturbed  inner_likelihood_std_perturbed  \\\n",
       "0                    0.095786                        0.197539   \n",
       "1                    0.072483                        0.173935   \n",
       "2                    0.017382                        0.070976   \n",
       "3                    0.054967                        0.149300   \n",
       "4                    0.016773                        0.068814   \n",
       "\n",
       "   correlation_perturbed  likelihood_mode_perturbed  \n",
       "0               0.642901                     lowest  \n",
       "1               0.801689                       high  \n",
       "2               0.766631                        mid  \n",
       "3               0.822567                       high  \n",
       "4               0.687584                     lowest  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coupled_columns = [\n",
    "    (col, f\"{col}_std\")\n",
    "    for col in perturbed_df.columns\n",
    "    if f\"{col}_std\" in perturbed_df.columns  # and \"likelihood\" in col\n",
    "]\n",
    "\n",
    "# # round the values\n",
    "# for col in perturbed_df.columns:\n",
    "#     # check if the column is a float\n",
    "#     if perturbed_df[col].dtype == float:\n",
    "#         perturbed_df[col] = perturbed_df[col].apply(lambda x: np.round(x, 3))\n",
    "#         real_df[col] = real_df[col].apply(lambda x: np.round(x, 3))\n",
    "#         # pad the column with zeros\n",
    "#         perturbed_df[col] = perturbed_df[col].apply(lambda x: f\"{x:0.3f}\")\n",
    "#         real_df[col] = real_df[col].apply(lambda x: f\"{x:0.3f}\")\n",
    "\n",
    "# # add the standard deviation to the value\n",
    "# for metric_col, std_col in coupled_columns:\n",
    "#     perturbed_df[metric_col] = [\n",
    "#         f\"{x} ± {y}\" for x, y in zip(perturbed_df[metric_col], perturbed_df[std_col])\n",
    "#     ]\n",
    "#     real_df[metric_col] = [\n",
    "#         f\"{x} ± {y}\" for x, y in zip(real_df[metric_col], real_df[std_col])\n",
    "#     ]\n",
    "\n",
    "#     del perturbed_df[std_col]\n",
    "#     del real_df[std_col]\n",
    "\n",
    "real_df.to_csv(DATA_DIR / \"real_df.tsv\", sep=\"\\t\", index=False)\n",
    "perturbed_df.to_csv(DATA_DIR / \"perturbed_df.tsv\", sep=\"\\t\", index=False)\n",
    "\n",
    "full_df = pd.merge(\n",
    "    left=real_df,\n",
    "    right=perturbed_df,\n",
    "    on=[\"encoder\", \"layer\"],\n",
    "    suffixes=[\"_real\", \"_perturbed\"],\n",
    ")\n",
    "full_df.to_csv(DATA_DIR / \"full_df.tsv\", sep=\"\\t\", index=False)\n",
    "full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bert-base-uncased', 9, 'lowest'),\n",
       " ('roberta-base', 11, 'high'),\n",
       " ('xlm-roberta-base', 11, 'mid'),\n",
       " ('roberta-large', 23, 'high'),\n",
       " ('distilbert-base-uncased', 4, 'lowest')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_keys = list(zip(full_df.encoder, full_df.layer, full_df.likelihood_mode_perturbed))\n",
    "table_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoders, _, likelihood_modes = list(zip(*table_keys))\n",
    "encoder2likelihood = list(zip(encoders, likelihood_modes))\n",
    "plot_df = correlation_df[correlation_df[[\"encoder\", \"likelihood_mode\"]].apply(tuple, axis=1).isin(encoder2likelihood)]\n",
    "\n",
    "plot_df.to_csv(DATA_DIR / \"plot_df.tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tueplots import figsizes\n",
    "import matplotlib.cm as cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update(figsizes.iclr2023(ncols=1, nrows=1, height_to_width_ratio=1))\n",
    "plt.rcParams[\"text.usetex\"] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 550x550 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoders, _, likelihood_modes = list(zip(*table_keys))\n",
    "encoder2likelihood = list(zip(encoders, likelihood_modes))\n",
    "plot_df = correlation_df[correlation_df[[\"encoder\", \"likelihood_mode\"]].apply(tuple, axis=1).isin(encoder2likelihood)]\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, sharey=True, sharex=True, squeeze=True)\n",
    "\n",
    "\n",
    "encoder2index = {encoder: i for i, encoder in enumerate(set(plot_df.encoder))}\n",
    "# populate the matrix\n",
    "z = np.zeros((len(set(plot_df.encoder)), len(set(plot_df.layer))))\n",
    "for i, row in plot_df.iterrows():\n",
    "    z[encoder2index[row.encoder], row.layer] = row.correlation\n",
    "z = np.ma.masked_where(z == 0, z)\n",
    "\n",
    "layers = [0, 5, 11, 17, 23]\n",
    "\n",
    "plt.xticks(labels=[str(a) for a in layers], ticks=layers)\n",
    "plt.yticks(labels=list(encoder2index.keys()), ticks=list(encoder2index.values()))\n",
    "\n",
    "\n",
    "image = ax.imshow(\n",
    "    z,\n",
    "    cmap=\"Spectral_r\",\n",
    "    origin=\"lower\",\n",
    "    # vmin=z.min(),\n",
    "    # vmax=z.max(),\n",
    ")\n",
    "\n",
    "cbar_ticks = np.linspace(z.min(), z.max(), 7)\n",
    "# ax.tick_params(axis=\"both\", labelsize=4)\n",
    "cbar = fig.colorbar(\n",
    "    image,\n",
    "    ax=ax,\n",
    "    ticks=[np.round(tick, 2) for tick in cbar_ticks],\n",
    "    fraction=0.015,\n",
    "    pad=0.04,\n",
    ")\n",
    "cbar.ax.set_ylabel(\"correlation $\\\\rho$\", rotation=90, labelpad=10)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(DATA_DIR / \"correlation.svg\", bbox_inches=\"tight\")\n",
    "!rsvg-convert -f pdf -o $DATA_DIR/correlation.pdf $DATA_DIR/correlation.svg\n",
    "!rm $DATA_DIR/correlation.svg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = likelihood2encoder2data[\"real\"][\"roberta-base\"]\n",
    "lemma_lengths = torch.as_tensor([x.shape[0] for x in data[\"lemma_ids\"]])\n",
    "sentence_lengths = torch.as_tensor([x.shape[0] for x in data[\"sentence_ids\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 550x275 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams.update(figsizes.iclr2023(ncols=2, nrows=1, height_to_width_ratio=1))\n",
    "\"\"\"Plot the token and sentence lengths.\"\"\"\n",
    "fig, axs = plt.subplots(nrows=1, ncols=2, sharey=False, sharex=False, squeeze=True)\n",
    "axs[0].hist(lemma_lengths, bins=20, log=True)\n",
    "axs[0].set_title(\"Token lengths\")\n",
    "axs[1].hist(sentence_lengths, bins=20, log=True)\n",
    "axs[1].set_title(\"Sentence lengths\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(DATA_DIR / \"dataset.svg\", bbox_inches=\"tight\")\n",
    "!rsvg-convert -f pdf -o $DATA_DIR/dataset.pdf $DATA_DIR/dataset.svg\n",
    "!rm $DATA_DIR/dataset.svg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert-base-uncased layer=9 likelihood_mode='lowest' diff_mean=-3.920451463468311e-11 diff_std=0.06103307381272316 mwu_u1=51.32635055205047 mwu_u2=47.3386238170347 mwu_p=0.5180216554517054\n",
      "roberta-base layer=11 likelihood_mode='high' diff_mean=-1.0370344166732437e-10 diff_std=0.05361169949173927 mwu_u1=40.64249802839117 mwu_u2=56.438732255520506 mwu_p=0.539919337431387\n",
      "xlm-roberta-base layer=11 likelihood_mode='mid' diff_mean=-7.057780054831042e-11 diff_std=0.07008374482393265 mwu_u1=48.461750788643535 mwu_u2=71.8762322555205 mwu_p=0.4753928649900121\n",
      "roberta-large layer=23 likelihood_mode='high' diff_mean=1.282185035228478e-11 diff_std=0.06332818418741226 mwu_u1=42.269420347003155 mwu_u2=54.81180993690852 mwu_p=0.5607710196606683\n",
      "distilbert-base-uncased layer=4 likelihood_mode='lowest' diff_mean=-2.061697340627333e-11 diff_std=0.05864017456769943 mwu_u1=43.836972594637224 mwu_u2=54.82800177444795 mwu_p=0.5527240156035247\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "\"\"\"Compute the Mann-Whitney U test for the attention distributions.\"\"\"\n",
    "for encoder, layer, likelihood_mode in table_keys:\n",
    "    perturbed_data = likelihood2encoder2data[likelihood_mode][encoder]\n",
    "    real_data = likelihood2encoder2data[\"real\"][encoder]\n",
    "\n",
    "    perturbed_attention = [attention[layer, :, :] for attention in perturbed_data[\"attention\"]]\n",
    "    real_attention = [attention[layer, :, :] for attention in real_data[\"attention\"]]\n",
    "\n",
    "    start_lemmas = real_data[\"start_lemma_index\"]\n",
    "    end_lemmas = real_data[\"end_lemma_index\"]\n",
    "\n",
    "    outer_orig_attention = [\n",
    "        torch.cat(\n",
    "            [\n",
    "                x[start_lemma:end_lemma, :start_lemma],\n",
    "                x[start_lemma:end_lemma, end_lemma:],\n",
    "            ],\n",
    "            dim=1,\n",
    "        ).mean(dim=0)\n",
    "        for x, start_lemma, end_lemma in zip(real_attention, start_lemmas, end_lemmas)\n",
    "    ]\n",
    "    outer_perturbed_attention = [\n",
    "        torch.cat(\n",
    "            [\n",
    "                x[start_lemma:end_lemma, :start_lemma],\n",
    "                x[start_lemma:end_lemma, end_lemma:],\n",
    "            ],\n",
    "            dim=1,\n",
    "        ).mean(dim=0)\n",
    "        for x, start_lemma, end_lemma in zip(perturbed_attention, start_lemmas, end_lemmas)\n",
    "    ]\n",
    "\n",
    "    mwu_u1 = []\n",
    "    mwu_u2 = []\n",
    "    mwu_p = []\n",
    "    for x, y in zip(outer_orig_attention, outer_perturbed_attention):\n",
    "        u1, p = mannwhitneyu(x, y, method=\"auto\")\n",
    "        u2 = x.shape[0] * y.shape[0] - u1\n",
    "        mwu_u1.append(u1)\n",
    "        mwu_u2.append(u2)\n",
    "        mwu_p.append(p)\n",
    "    mwu_u1 = torch.as_tensor(mwu_u1)\n",
    "    mwu_u2 = torch.as_tensor(mwu_u2)\n",
    "    mwu_p = torch.as_tensor(mwu_p)\n",
    "\n",
    "    mwu_u1 = mwu_u1.mean().item()\n",
    "    mwu_u2 = mwu_u2.mean().item()\n",
    "    mwu_p = mwu_p.mean().item()\n",
    "\n",
    "    diff_mean = (\n",
    "        torch.stack(\n",
    "            [\n",
    "                (x - y)[start_lemma:end_lemma, :].mean(dim=1).mean()\n",
    "                for x, y, start_lemma, end_lemma in zip(perturbed_attention, real_attention, start_lemmas, end_lemmas)\n",
    "            ]\n",
    "        )\n",
    "        .mean()\n",
    "        .item()\n",
    "    )\n",
    "    diff_std = (\n",
    "        torch.stack(\n",
    "            [\n",
    "                (x - y)[start_lemma:end_lemma, :].std(dim=1).mean()\n",
    "                for x, y, start_lemma, end_lemma in zip(perturbed_attention, real_attention, start_lemmas, end_lemmas)\n",
    "            ]\n",
    "        )\n",
    "        .mean()\n",
    "        .item()\n",
    "    )\n",
    "\n",
    "    print(f\"{encoder} {layer=} {likelihood_mode=} {diff_mean=} {diff_std=} {mwu_u1=} {mwu_u2=} {mwu_p=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "low 0.041193630546331406\n",
      "lowest 0.032791584730148315\n",
      "high 0.06694696843624115\n",
      "real 0.2640671730041504\n",
      "highest 0.399607390165329\n",
      "mid 0.3457651734352112\n"
     ]
    }
   ],
   "source": [
    "x = []\n",
    "for likelihood, encoder2data in likelihood2encoder2data.items():\n",
    "    for encoder_name, encoder_data in encoder2data.items():\n",
    "        x.append(encoder_data[\"inner_likelihoods_mean\"].mean().item())\n",
    "    print(likelihood, torch.as_tensor(x).mean().item())\n",
    "# x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from attlike.utils import data_to_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['low', 'lowest', 'high', 'real', 'highest', 'mid'])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "likelihood2df = {}\n",
    "for likelihood, encoder2data in likelihood2encoder2data.items():\n",
    "    likelihood2df[likelihood] = data_to_df(encoder2data)\n",
    "likelihood2df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "(DATA_DIR / \"likelihood_df\").mkdir(exist_ok=True)\n",
    "for likelihood, df in likelihood2df.items():\n",
    "    df.to_csv(DATA_DIR / \"likelihood_df\" / f\"{likelihood}.tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['high', 'real', 'highest', 'lowest', 'mid', 'low'])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "likelihood2df = {\n",
    "    likelihood_file.name.split(\".\")[0]: pd.read_csv(likelihood_file, sep=\"\\t\")\n",
    "    for likelihood_file in (DATA_DIR / \"likelihood_df\").iterdir()\n",
    "    if likelihood_file.name.endswith(\".tsv\")\n",
    "}\n",
    "likelihood2df = {likelihood: df for likelihood, df in likelihood2df.items()}\n",
    "likelihood2df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>encoder</th>\n",
       "      <th>layer</th>\n",
       "      <th>attention</th>\n",
       "      <th>inner_attention</th>\n",
       "      <th>outer_attention</th>\n",
       "      <th>likelihood</th>\n",
       "      <th>likelihood_mode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.117414</td>\n",
       "      <td>0.111032</td>\n",
       "      <td>2.304286e-03</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.126819</td>\n",
       "      <td>0.090610</td>\n",
       "      <td>4.574996e-04</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.127791</td>\n",
       "      <td>0.099719</td>\n",
       "      <td>7.362875e-04</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.140764</td>\n",
       "      <td>0.099588</td>\n",
       "      <td>9.825145e-02</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>0</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.076755</td>\n",
       "      <td>0.049384</td>\n",
       "      <td>5.335055e-01</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1339003</th>\n",
       "      <td>distilbert-base-uncased</td>\n",
       "      <td>5</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.055004</td>\n",
       "      <td>0.067153</td>\n",
       "      <td>6.818367e-03</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1339004</th>\n",
       "      <td>distilbert-base-uncased</td>\n",
       "      <td>5</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.020183</td>\n",
       "      <td>0.058958</td>\n",
       "      <td>1.478052e-06</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1339005</th>\n",
       "      <td>distilbert-base-uncased</td>\n",
       "      <td>5</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.037906</td>\n",
       "      <td>0.084631</td>\n",
       "      <td>5.705641e-07</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1339006</th>\n",
       "      <td>distilbert-base-uncased</td>\n",
       "      <td>5</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.039549</td>\n",
       "      <td>0.084584</td>\n",
       "      <td>6.903951e-06</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1339007</th>\n",
       "      <td>distilbert-base-uncased</td>\n",
       "      <td>5</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.017003</td>\n",
       "      <td>0.066888</td>\n",
       "      <td>1.610402e-07</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8034048 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         encoder  layer  attention  inner_attention  \\\n",
       "0              bert-base-uncased      0   0.111111         0.117414   \n",
       "1              bert-base-uncased      0   0.090909         0.126819   \n",
       "2              bert-base-uncased      0   0.100000         0.127791   \n",
       "3              bert-base-uncased      0   0.100000         0.140764   \n",
       "4              bert-base-uncased      0   0.050000         0.076755   \n",
       "...                          ...    ...        ...              ...   \n",
       "1339003  distilbert-base-uncased      5   0.066667         0.055004   \n",
       "1339004  distilbert-base-uncased      5   0.058824         0.020183   \n",
       "1339005  distilbert-base-uncased      5   0.083333         0.037906   \n",
       "1339006  distilbert-base-uncased      5   0.083333         0.039549   \n",
       "1339007  distilbert-base-uncased      5   0.066667         0.017003   \n",
       "\n",
       "         outer_attention    likelihood likelihood_mode  \n",
       "0               0.111032  2.304286e-03            high  \n",
       "1               0.090610  4.574996e-04            high  \n",
       "2               0.099719  7.362875e-04            high  \n",
       "3               0.099588  9.825145e-02            high  \n",
       "4               0.049384  5.335055e-01            high  \n",
       "...                  ...           ...             ...  \n",
       "1339003         0.067153  6.818367e-03             low  \n",
       "1339004         0.058958  1.478052e-06             low  \n",
       "1339005         0.084631  5.705641e-07             low  \n",
       "1339006         0.084584  6.903951e-06             low  \n",
       "1339007         0.066888  1.610402e-07             low  \n",
       "\n",
       "[8034048 rows x 7 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs = []\n",
    "for likelihood, df in likelihood2df.items():\n",
    "    df[\"likelihood_mode\"] = likelihood\n",
    "    dfs.append(df)\n",
    "df = pd.concat(dfs)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_59302/3104618255.py:3: FutureWarning: ['encoder'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
      "  df.groupby([\"likelihood_mode\", \"layer\"]).aggregate([np.mean, np.std])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">attention</th>\n",
       "      <th colspan=\"2\" halign=\"left\">inner_attention</th>\n",
       "      <th colspan=\"2\" halign=\"left\">outer_attention</th>\n",
       "      <th colspan=\"2\" halign=\"left\">likelihood</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>likelihood_mode</th>\n",
       "      <th>layer</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">high</th>\n",
       "      <th>0</th>\n",
       "      <td>0.097225</td>\n",
       "      <td>0.025344</td>\n",
       "      <td>0.147253</td>\n",
       "      <td>0.064885</td>\n",
       "      <td>0.096165</td>\n",
       "      <td>0.025268</td>\n",
       "      <td>0.135258</td>\n",
       "      <td>0.244015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.097225</td>\n",
       "      <td>0.025344</td>\n",
       "      <td>0.064847</td>\n",
       "      <td>0.033396</td>\n",
       "      <td>0.098084</td>\n",
       "      <td>0.026038</td>\n",
       "      <td>0.135258</td>\n",
       "      <td>0.244015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.097225</td>\n",
       "      <td>0.025344</td>\n",
       "      <td>0.055197</td>\n",
       "      <td>0.026383</td>\n",
       "      <td>0.098424</td>\n",
       "      <td>0.026028</td>\n",
       "      <td>0.135258</td>\n",
       "      <td>0.244015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.097225</td>\n",
       "      <td>0.025344</td>\n",
       "      <td>0.047934</td>\n",
       "      <td>0.026449</td>\n",
       "      <td>0.098482</td>\n",
       "      <td>0.026088</td>\n",
       "      <td>0.135258</td>\n",
       "      <td>0.244015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.097225</td>\n",
       "      <td>0.025344</td>\n",
       "      <td>0.053746</td>\n",
       "      <td>0.022739</td>\n",
       "      <td>0.098434</td>\n",
       "      <td>0.025984</td>\n",
       "      <td>0.135258</td>\n",
       "      <td>0.244015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">real</th>\n",
       "      <th>19</th>\n",
       "      <td>0.099556</td>\n",
       "      <td>0.024887</td>\n",
       "      <td>0.045265</td>\n",
       "      <td>0.013375</td>\n",
       "      <td>0.101167</td>\n",
       "      <td>0.025567</td>\n",
       "      <td>0.947395</td>\n",
       "      <td>0.171740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.099556</td>\n",
       "      <td>0.024887</td>\n",
       "      <td>0.054505</td>\n",
       "      <td>0.018936</td>\n",
       "      <td>0.100765</td>\n",
       "      <td>0.025543</td>\n",
       "      <td>0.947395</td>\n",
       "      <td>0.171740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.099556</td>\n",
       "      <td>0.024887</td>\n",
       "      <td>0.067770</td>\n",
       "      <td>0.034302</td>\n",
       "      <td>0.100099</td>\n",
       "      <td>0.025618</td>\n",
       "      <td>0.947395</td>\n",
       "      <td>0.171740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.099556</td>\n",
       "      <td>0.024887</td>\n",
       "      <td>0.051660</td>\n",
       "      <td>0.029507</td>\n",
       "      <td>0.100571</td>\n",
       "      <td>0.025612</td>\n",
       "      <td>0.947395</td>\n",
       "      <td>0.171740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.099556</td>\n",
       "      <td>0.024887</td>\n",
       "      <td>0.133954</td>\n",
       "      <td>0.040175</td>\n",
       "      <td>0.099075</td>\n",
       "      <td>0.025067</td>\n",
       "      <td>0.947395</td>\n",
       "      <td>0.171740</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      attention           inner_attention            \\\n",
       "                           mean       std            mean       std   \n",
       "likelihood_mode layer                                                 \n",
       "high            0      0.097225  0.025344        0.147253  0.064885   \n",
       "                1      0.097225  0.025344        0.064847  0.033396   \n",
       "                2      0.097225  0.025344        0.055197  0.026383   \n",
       "                3      0.097225  0.025344        0.047934  0.026449   \n",
       "                4      0.097225  0.025344        0.053746  0.022739   \n",
       "...                         ...       ...             ...       ...   \n",
       "real            19     0.099556  0.024887        0.045265  0.013375   \n",
       "                20     0.099556  0.024887        0.054505  0.018936   \n",
       "                21     0.099556  0.024887        0.067770  0.034302   \n",
       "                22     0.099556  0.024887        0.051660  0.029507   \n",
       "                23     0.099556  0.024887        0.133954  0.040175   \n",
       "\n",
       "                      outer_attention           likelihood            \n",
       "                                 mean       std       mean       std  \n",
       "likelihood_mode layer                                                 \n",
       "high            0            0.096165  0.025268   0.135258  0.244015  \n",
       "                1            0.098084  0.026038   0.135258  0.244015  \n",
       "                2            0.098424  0.026028   0.135258  0.244015  \n",
       "                3            0.098482  0.026088   0.135258  0.244015  \n",
       "                4            0.098434  0.025984   0.135258  0.244015  \n",
       "...                               ...       ...        ...       ...  \n",
       "real            19           0.101167  0.025567   0.947395  0.171740  \n",
       "                20           0.100765  0.025543   0.947395  0.171740  \n",
       "                21           0.100099  0.025618   0.947395  0.171740  \n",
       "                22           0.100571  0.025612   0.947395  0.171740  \n",
       "                23           0.099075  0.025067   0.947395  0.171740  \n",
       "\n",
       "[144 rows x 8 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "df.groupby([\"likelihood_mode\", \"layer\"]).aggregate([np.mean, np.std])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "bingroup": "x",
         "hovertemplate": "variable=attention<br>value=%{x}<br>count=%{y}<extra></extra>",
         "legendgroup": "attention",
         "marker": {
          "color": "#636efa",
          "opacity": 0.5,
          "pattern": {
           "shape": ""
          }
         },
         "name": "attention",
         "nbinsx": 500,
         "offsetgroup": "attention",
         "orientation": "v",
         "showlegend": true,
         "type": "histogram",
         "x": [
          0.0988103374838829,
          0.0988103374838829,
          0.0988103374838829,
          0.0988103374838829,
          0.0988103374838829,
          0.0988103374838829,
          0.0988103374838829,
          0.0988103374838829,
          0.0988103374838829,
          0.0988103374838829,
          0.0988103374838829,
          0.0988103374838829,
          0.09955641627311707,
          0.09955641627311707,
          0.09955641627311707,
          0.09955641627311707,
          0.09955641627311707,
          0.09955641627311707,
          0.09955641627311707,
          0.09955641627311707,
          0.09955641627311707,
          0.09955641627311707,
          0.09955641627311707,
          0.09955641627311707,
          0.08939166367053986,
          0.08939166367053986,
          0.08939166367053986,
          0.08939166367053986,
          0.08939166367053986,
          0.08939166367053986,
          0.08939166367053986,
          0.08939166367053986,
          0.08939166367053986,
          0.08939166367053986,
          0.08939166367053986,
          0.08939166367053986,
          0.09955640882253647,
          0.09955641627311707,
          0.09955641627311707,
          0.09955641627311707,
          0.09955640882253647,
          0.09955640882253647,
          0.09955641627311707,
          0.09955641627311707,
          0.09955641627311707,
          0.09955641627311707,
          0.09955641627311707,
          0.09955640882253647,
          0.09955640882253647,
          0.09955640882253647,
          0.09955641627311707,
          0.09955640882253647,
          0.09955640882253647,
          0.09955640882253647,
          0.09955641627311707,
          0.09955640882253647,
          0.09955641627311707,
          0.09955640882253647,
          0.09955640882253647,
          0.09955641627311707,
          0.0988103374838829,
          0.0988103374838829,
          0.0988103374838829,
          0.0988103374838829,
          0.0988103374838829,
          0.0988103374838829
         ],
         "xaxis": "x",
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "hovertemplate": "variable=attention<br>value=%{x}<extra></extra>",
         "legendgroup": "attention",
         "marker": {
          "color": "#636efa"
         },
         "name": "attention",
         "notched": true,
         "offsetgroup": "attention",
         "showlegend": false,
         "type": "box",
         "x": [
          0.0988103374838829,
          0.0988103374838829,
          0.0988103374838829,
          0.0988103374838829,
          0.0988103374838829,
          0.0988103374838829,
          0.0988103374838829,
          0.0988103374838829,
          0.0988103374838829,
          0.0988103374838829,
          0.0988103374838829,
          0.0988103374838829,
          0.09955641627311707,
          0.09955641627311707,
          0.09955641627311707,
          0.09955641627311707,
          0.09955641627311707,
          0.09955641627311707,
          0.09955641627311707,
          0.09955641627311707,
          0.09955641627311707,
          0.09955641627311707,
          0.09955641627311707,
          0.09955641627311707,
          0.08939166367053986,
          0.08939166367053986,
          0.08939166367053986,
          0.08939166367053986,
          0.08939166367053986,
          0.08939166367053986,
          0.08939166367053986,
          0.08939166367053986,
          0.08939166367053986,
          0.08939166367053986,
          0.08939166367053986,
          0.08939166367053986,
          0.09955640882253647,
          0.09955641627311707,
          0.09955641627311707,
          0.09955641627311707,
          0.09955640882253647,
          0.09955640882253647,
          0.09955641627311707,
          0.09955641627311707,
          0.09955641627311707,
          0.09955641627311707,
          0.09955641627311707,
          0.09955640882253647,
          0.09955640882253647,
          0.09955640882253647,
          0.09955641627311707,
          0.09955640882253647,
          0.09955640882253647,
          0.09955640882253647,
          0.09955641627311707,
          0.09955640882253647,
          0.09955641627311707,
          0.09955640882253647,
          0.09955640882253647,
          0.09955641627311707,
          0.0988103374838829,
          0.0988103374838829,
          0.0988103374838829,
          0.0988103374838829,
          0.0988103374838829,
          0.0988103374838829
         ],
         "xaxis": "x2",
         "yaxis": "y2"
        },
        {
         "alignmentgroup": "True",
         "bingroup": "x",
         "hovertemplate": "variable=outer_attention<br>value=%{x}<br>count=%{y}<extra></extra>",
         "legendgroup": "outer_attention",
         "marker": {
          "color": "#EF553B",
          "opacity": 0.5,
          "pattern": {
           "shape": ""
          }
         },
         "name": "outer_attention",
         "nbinsx": 500,
         "offsetgroup": "outer_attention",
         "orientation": "v",
         "showlegend": true,
         "type": "histogram",
         "x": [
          0.0981697365641594,
          0.0999290719628334,
          0.09941013157367706,
          0.1001763641834259,
          0.09992665797472,
          0.10068748146295547,
          0.10036390274763107,
          0.10061275213956833,
          0.1008700281381607,
          0.09991586208343506,
          0.09989567846059799,
          0.10020970553159714,
          0.0978851169347763,
          0.10056623816490173,
          0.10062894970178604,
          0.10103892534971237,
          0.10096574574708939,
          0.10115548223257065,
          0.10112284868955612,
          0.10042685270309448,
          0.10097833722829819,
          0.10049359500408173,
          0.10044731944799423,
          0.09933426976203918,
          0.0887787938117981,
          0.0896756649017334,
          0.09032629430294037,
          0.0902719721198082,
          0.09028705954551697,
          0.09025153517723083,
          0.0910467654466629,
          0.09065316617488861,
          0.0906219407916069,
          0.08980362862348557,
          0.08991929143667221,
          0.08898038417100906,
          0.09781801700592041,
          0.10065552592277527,
          0.10102734714746475,
          0.10079331696033478,
          0.10095973312854767,
          0.10171405225992203,
          0.10150617361068726,
          0.10074622929096222,
          0.10052841156721115,
          0.10086045414209366,
          0.10101645439863205,
          0.10100935399532318,
          0.10096011310815811,
          0.10141939669847488,
          0.10164204239845276,
          0.10144922882318497,
          0.10141067206859589,
          0.10144193470478058,
          0.10158619284629822,
          0.10116665065288544,
          0.10076490789651871,
          0.1000988706946373,
          0.10057063400745392,
          0.09907520562410355,
          0.09861525148153305,
          0.09900883585214615,
          0.10022962093353271,
          0.10035404562950134,
          0.10017812252044678,
          0.10030785202980042
         ],
         "xaxis": "x",
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "hovertemplate": "variable=outer_attention<br>value=%{x}<extra></extra>",
         "legendgroup": "outer_attention",
         "marker": {
          "color": "#EF553B"
         },
         "name": "outer_attention",
         "notched": true,
         "offsetgroup": "outer_attention",
         "showlegend": false,
         "type": "box",
         "x": [
          0.0981697365641594,
          0.0999290719628334,
          0.09941013157367706,
          0.1001763641834259,
          0.09992665797472,
          0.10068748146295547,
          0.10036390274763107,
          0.10061275213956833,
          0.1008700281381607,
          0.09991586208343506,
          0.09989567846059799,
          0.10020970553159714,
          0.0978851169347763,
          0.10056623816490173,
          0.10062894970178604,
          0.10103892534971237,
          0.10096574574708939,
          0.10115548223257065,
          0.10112284868955612,
          0.10042685270309448,
          0.10097833722829819,
          0.10049359500408173,
          0.10044731944799423,
          0.09933426976203918,
          0.0887787938117981,
          0.0896756649017334,
          0.09032629430294037,
          0.0902719721198082,
          0.09028705954551697,
          0.09025153517723083,
          0.0910467654466629,
          0.09065316617488861,
          0.0906219407916069,
          0.08980362862348557,
          0.08991929143667221,
          0.08898038417100906,
          0.09781801700592041,
          0.10065552592277527,
          0.10102734714746475,
          0.10079331696033478,
          0.10095973312854767,
          0.10171405225992203,
          0.10150617361068726,
          0.10074622929096222,
          0.10052841156721115,
          0.10086045414209366,
          0.10101645439863205,
          0.10100935399532318,
          0.10096011310815811,
          0.10141939669847488,
          0.10164204239845276,
          0.10144922882318497,
          0.10141067206859589,
          0.10144193470478058,
          0.10158619284629822,
          0.10116665065288544,
          0.10076490789651871,
          0.1000988706946373,
          0.10057063400745392,
          0.09907520562410355,
          0.09861525148153305,
          0.09900883585214615,
          0.10022962093353271,
          0.10035404562950134,
          0.10017812252044678,
          0.10030785202980042
         ],
         "xaxis": "x2",
         "yaxis": "y2"
        },
        {
         "alignmentgroup": "True",
         "bingroup": "x",
         "hovertemplate": "variable=inner_attention<br>value=%{x}<br>count=%{y}<extra></extra>",
         "legendgroup": "inner_attention",
         "marker": {
          "color": "#00cc96",
          "opacity": 0.5,
          "pattern": {
           "shape": ""
          }
         },
         "name": "inner_attention",
         "nbinsx": 500,
         "offsetgroup": "inner_attention",
         "orientation": "v",
         "showlegend": true,
         "type": "histogram",
         "x": [
          0.10976474732160568,
          0.06164078414440155,
          0.07811370491981506,
          0.046967100352048874,
          0.056086327880620956,
          0.034206490963697433,
          0.04000081494450569,
          0.037829093635082245,
          0.038168974220752716,
          0.0749867707490921,
          0.08924712240695953,
          0.07010364532470703,
          0.15839633345603943,
          0.05151280388236046,
          0.057363804429769516,
          0.04686513915657997,
          0.051701050251722336,
          0.04750640317797661,
          0.05165762081742287,
          0.061592306941747665,
          0.044816140085458755,
          0.054314449429512024,
          0.06612347811460495,
          0.12432920187711716,
          0.12268895655870438,
          0.07072897255420685,
          0.057980142533779144,
          0.07459571957588196,
          0.06138063222169876,
          0.0676095262169838,
          0.044997379183769226,
          0.05425559729337692,
          0.055339571088552475,
          0.08308011293411255,
          0.08210905641317368,
          0.131850004196167,
          0.19946736097335815,
          0.04709809273481369,
          0.041463322937488556,
          0.04603061452507973,
          0.05339200794696808,
          0.026139508932828903,
          0.02940285950899124,
          0.062496036291122437,
          0.07882093638181686,
          0.05676930025219917,
          0.052816569805145264,
          0.052417557686567307,
          0.05167486518621445,
          0.04243774339556694,
          0.032193198800086975,
          0.03993823006749153,
          0.042416561394929886,
          0.04206698760390282,
          0.03809809312224388,
          0.04526548832654953,
          0.054504863917827606,
          0.06777042895555496,
          0.05165978521108627,
          0.13395416736602783,
          0.09622063487768173,
          0.0912751853466034,
          0.04485118389129639,
          0.03900981694459915,
          0.06453957408666611,
          0.06262338161468506
         ],
         "xaxis": "x",
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "hovertemplate": "variable=inner_attention<br>value=%{x}<extra></extra>",
         "legendgroup": "inner_attention",
         "marker": {
          "color": "#00cc96"
         },
         "name": "inner_attention",
         "notched": true,
         "offsetgroup": "inner_attention",
         "showlegend": false,
         "type": "box",
         "x": [
          0.10976474732160568,
          0.06164078414440155,
          0.07811370491981506,
          0.046967100352048874,
          0.056086327880620956,
          0.034206490963697433,
          0.04000081494450569,
          0.037829093635082245,
          0.038168974220752716,
          0.0749867707490921,
          0.08924712240695953,
          0.07010364532470703,
          0.15839633345603943,
          0.05151280388236046,
          0.057363804429769516,
          0.04686513915657997,
          0.051701050251722336,
          0.04750640317797661,
          0.05165762081742287,
          0.061592306941747665,
          0.044816140085458755,
          0.054314449429512024,
          0.06612347811460495,
          0.12432920187711716,
          0.12268895655870438,
          0.07072897255420685,
          0.057980142533779144,
          0.07459571957588196,
          0.06138063222169876,
          0.0676095262169838,
          0.044997379183769226,
          0.05425559729337692,
          0.055339571088552475,
          0.08308011293411255,
          0.08210905641317368,
          0.131850004196167,
          0.19946736097335815,
          0.04709809273481369,
          0.041463322937488556,
          0.04603061452507973,
          0.05339200794696808,
          0.026139508932828903,
          0.02940285950899124,
          0.062496036291122437,
          0.07882093638181686,
          0.05676930025219917,
          0.052816569805145264,
          0.052417557686567307,
          0.05167486518621445,
          0.04243774339556694,
          0.032193198800086975,
          0.03993823006749153,
          0.042416561394929886,
          0.04206698760390282,
          0.03809809312224388,
          0.04526548832654953,
          0.054504863917827606,
          0.06777042895555496,
          0.05165978521108627,
          0.13395416736602783,
          0.09622063487768173,
          0.0912751853466034,
          0.04485118389129639,
          0.03900981694459915,
          0.06453957408666611,
          0.06262338161468506
         ],
         "xaxis": "x2",
         "yaxis": "y2"
        }
       ],
       "layout": {
        "barmode": "overlay",
        "legend": {
         "title": {
          "text": "variable"
         },
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Real Attention"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "value"
         }
        },
        "xaxis2": {
         "anchor": "y2",
         "domain": [
          0,
          1
         ],
         "matches": "x",
         "showgrid": true,
         "showticklabels": false
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          0.7326
         ],
         "title": {
          "text": "count"
         }
        },
        "yaxis2": {
         "anchor": "x2",
         "domain": [
          0.7426,
          1
         ],
         "matches": "y2",
         "showgrid": false,
         "showline": false,
         "showticklabels": false,
         "ticks": ""
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"Plot the attention distributions.\"\"\"\n",
    "px.histogram(\n",
    "    real_df,\n",
    "    x=[\"attention\", \"outer_attention\", \"inner_attention\"],\n",
    "    marginal=\"box\",\n",
    "    barmode=\"overlay\",\n",
    "    # facet_row=\"encoder\",\n",
    "    nbins=500,\n",
    "    title=\"Real Attention\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "attlike",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "e190c64035ea994edb35a95c6b38ed865775c81e6eda414744506182cf5d7912"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
